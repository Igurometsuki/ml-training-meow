import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Sample data (replace with your actual data source if available)
data = {
    'size': [1500, 2000, 1800, 2500, 1200, 1700, 2300, 1100, 1900, 2100],
    'beds': [3, 4, 3, 5, 2, 3, 4, 2, 4, 3],
    'bathrooms': [2, 2.5, 2, 3, 1.5, 2, 2.5, 1, 2.5, 2],
    'age': [10, 15, 8, 5, 20, 12, 7, 25, 18, 14],
    'price': [300000, 420000, 350000, 500000, 250000, 380000, 480000, 220000, 400000, 450000]
}

# Create a pandas DataFrame from the sample data
df = pd.DataFrame(data)

# Select features and target variable
features = ['size', 'beds', 'bathrooms', 'age']
target = 'price'

# Separate features and target data
X = df[features]
y = df[target]

# Split data into training and testing sets (80%/20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create the Linear Regression model
model = LinearRegression()

# Train the model on the training data
model.fit(X_train, y_train)

# Make predictions on the testing set
y_predicted = model.predict(X_test)

# Evaluate the model performance using Mean Squared Error (MSE)
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test, y_predicted)
print("Mean Squared Error:", mse)

# Alternatively, calculate R-squared for evaluation (higher value indicates better fit)
from sklearn.metrics import r2_score
r2 = r2_score(y_test, y_predicted)
print("R-squared:", r2)

# Now you can use the trained model to predict prices for new houses with unseen data (corrected):
new_house = pd.DataFrame([{'size': 2200, 'beds': 3, 'bathrooms': 2.5, 'age': 9}])  # Create a DataFrame with 1 row
predicted_price = model.predict(new_house)[0]  # Pass the DataFrame directly to predict
print("Predicted Price for the new house:", predicted_price)
